
import configparser
import logging
import json
import os
import re
import tempfile
import threading
import yaml
import queue

from git import Repo

from debian import deb822
from debian.changelog import Changelog
from cvetracker.config import CONFIG

from pyrpm.spec import Spec


class NoGitBranchException(Exception):
    def __init__(self, message):
        super().__init__(message)


class FileNotFoundException(Exception):
    def __init__(self, message):
        super().__init__(message)


class GitRepo(object):
    log = logging.getLogger(__name__)

    def __init__(self, repo=None, store_prefix=None, git_prefix=None):
        self._ = repo
        self.store_prefix = store_prefix
        self.git_prefix = git_prefix

    def import_project(self, project, branch='master', fetch=True):
        self._ = None
        self.log.info("Importing project '{}' ({}) ..."
                      .format(project, branch))
        target_path = os.path.join(self.store_prefix, project)
        os.makedirs(target_path, exist_ok=True)
        if not os.path.exists(os.path.join(target_path, '.git')):
            self.log.debug("Creating new repo '{}' at '{}' ..."
                           .format(project, target_path))
            self._ = Repo.init(target_path)
            origin = self.remote('origin', self.git_prefix + '/' + project)
            fetch = True
        else:
            self.log.debug("Using existing repo at '{}' ..."
                           .format(target_path))
            self._ = Repo(target_path)
            origin = self.remote('origin')

        if fetch:
            origin.fetch()

        try:
            self.checkout(branch)
        except IndexError as e:
            raise NoGitBranchException(e)
        except: # noqa
            self.deep_clean(branch)

        # self._.git.pull()

    def remote(self, name, url=None):
        remote = getattr(self._.remotes, name, None)
        if remote is None:
            remote = self._.create_remote(name, url)

        return remote

    def deep_clean(self, branch='master'):
        self.log.debug("Performing deep repo clean ...")
        git = self._.git
        first_commit = git.rev_list('--max-parents=0', 'HEAD').split('\n')[0]
        git.reset('--hard', first_commit)
        git.clean('-f', '-d', '-x')
        git.checkout(branch)
        git.pull()

    def checkout(self, branch='master'):
        self.log.debug("Working dir '{}', checking out '{}' ..."
                       .format(self._.working_dir, branch))
        if self._.is_dirty():
            self.deep_clean()

        if branch in self._.heads:
            self._.heads[branch].checkout()
        else:
            origin = self._.remotes.origin
            if branch not in origin.refs:
                origin.fetch()
            self._.create_head(branch, origin.refs[branch])\
                .set_tracking_branch(origin.refs[branch]).checkout()
        self._.git.pull()


class GitProjectScanner(object):
    def __init__(self, *args, configfile=None, filename='packages.json',
                 thread_count=10, **kwargs):
        self.log = logging.getLogger()
        self.configfile = configfile or CONFIG.configfile
        self.filename = filename
        self.threads = []
        self.thread_count = thread_count

    def start(self):
        result_queue = queue.Queue()
        result_queue.empty()

        producer = GitProjectScannerProducer(
            name='Producer',
            thread_count=self.thread_count,
            configfile=self.configfile,
            result_queue=result_queue,
        )

        consumer = GitProjectScannerConsumer(
            name='Consumer',
            configfile=self.configfile,
            filename=self.filename,
            result_queue=result_queue,
        )

        producer.start()
        consumer.start()
        producer.join()
        consumer.disable()
        consumer.join()


class ProjectConfigGenerator(object):
    def __init__(self, config):
        self.config = config
        self.scanner_config = yaml.load(open(config['scanner_config']))

    def _projects(self):
        for name, opts in self.scanner_config['sources'].items():
            opts.setdefault('hostname', name)
            opts.setdefault('protocol', 'https')
            if opts['protocol'] == 'https':
                auth = opts.get('auth', 'anonymous')
                if auth == 'anonymous':
                    fmt = '{protocol}://{hostname}'
                elif auth == 'fake':
                    fmt = '{protocol}://x:x@{hostname}'
                else:
                    fmt = '{protocol}://{username}:{password}@{hostname}'
            elif opts['protocol'] == 'ssh':
                opts.setdefault('port', 29418)
                fmt = '{protocol}://{username}@{hostname}:{port}'
            else:
                raise Exception("Unknown GIT protocol '{}'"
                                .format(opts['protocol']))

            git_prefix = fmt.format(**opts)
            projects_filename = opts.get('projects',
                                         '{}.projects.yaml'.format(name))
            projects = yaml.load(open(projects_filename))

            for x in projects:
                if isinstance(x, dict):
                    project_name = x['project']
                else:
                    project_name = x
                yield {
                    'source': name,
                    'project': project_name,
                    'git_prefix': git_prefix,
                    'git_store_prefix': os.path.join(
                        self.config.get('store_prefix'), name
                    ),
                }

    def __call__(self):
        for x in self._projects():
            for product_mapping in self.scanner_config['product-mapping']:
                if product_mapping['source'] != x['source']:
                    continue
                # project_mappings = product_mapping['project-mapping']
                for project_mapping in product_mapping['project-mapping']:
                    if re.match(project_mapping['pattern'], x['project']):
                        data = {}
                        for k, v in product_mapping.items():
                            if k in ['project-mapping', ]:
                                continue
                            data[k] = v
                        data.update(project_mapping)

                        result = {}
                        result.update(x)
                        result['product_data'] = data
                        yield result


class BaseThread(threading.Thread):
    def __init__(self, *args, name=None, configfile=None, **kwargs):
        super().__init__(*args, name=name, **kwargs)
        self.log = logging.getLogger(self.name)
        self.configfile = configfile
        self.config = configparser.ConfigParser(os.environ)
        self.config.read(configfile)
        self.enabled = True

    def disable(self):
        self.enabled = False


class GitProjectScannerProducer(BaseThread):
    def __init__(self, *args, thread_count=1, result_queue=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.thread_count = thread_count
        self.threads = []
        self.task_queue = queue.Queue(self.thread_count)
        self.task_queue.empty()
        self.result_queue = result_queue

    def run(self):
        self.start_threads()
        self.produce_data()
        self.stop_threads()

    def start_threads(self):
        for id in range(self.thread_count):
            t = GitProjectScannerWorker(
                name='Worker-{}'.format(id),
                configfile=self.configfile,
                task_queue=self.task_queue,
                result_queue=self.result_queue
            )
            self.threads.append(t)
            t.start()

    def stop_threads(self):
        for t in self.threads:
            task = {
                'control': {
                    'command': 'stop',
                }
            }
            self.log.debug("Sending data to task_queue '{}'".format(task))
            self.task_queue.put(task)

        for t in self.threads:
            self.log.debug('Joining thread {}'.format(t.name))
            t.join()
            self.log.debug('Thread {} stopped'.format(t.name))

    def produce_data(self):
        project_config_generator = ProjectConfigGenerator(
            dict(self.config.items('git')))

        for project_config in project_config_generator():
            task = {
                'data': [],
            }
            product_data = project_config.pop('product_data')
            task['data'].append({
                'project_config': project_config,
                'product_data': product_data,
            })

            if len(task['data']):
                self.log.debug("Sending data to task_queue '{}'".format(task))
                self.task_queue.put(task)

        self.log.debug('All data have been sent to task_queue')


class GitProjectScannerConsumer(BaseThread):
    def __init__(self, *args, result_queue=None, filename='packages.json',
                 **kwargs):
        super().__init__(*args, **kwargs)
        self.result_queue = result_queue
        self.filename = filename

    def run(self):
        self.log.debug('Starting consumer')
        while self.enabled:
            try:
                task = self.result_queue.get(timeout=1.0)
            except queue.Empty:
                continue
            if task is None:
                continue
            self.log.debug("Got task from result_queue '{}'".format(task))
            data = task.get('data', [])

            with open(self.filename, 'a') as ofile:
                ofile.write('{}\n'.format(json.dumps(data)))


class GitProjectScannerWorker(BaseThread):
    def __init__(self, *args, task_queue=None, result_queue=None, **kwargs):
        super().__init__(*args, **kwargs)
        self.task_queue = task_queue
        self.result_queue = result_queue

    def run(self):
        self.log.debug('Starting worker')
        while self.enabled:
            try:
                task = self.task_queue.get(timeout=1.0)
            except queue.Empty:
                continue
            if task is None:
                continue
            self.log.debug("Got task from task_queue '{}'".format(task))
            control = task.get('control', None)
            if control:
                command = control.get('command')
                if command == 'stop':
                    self.log.debug(
                        "Stopping worker by request from task_queue")
                    return
            try:
                self.process_task(task)
            except: # noqa
                self.log.exception("Something went wrong")

    def process_task(self, task):
        for data in task.get('data', []):
            project_config = data.pop('project_config')
            product_data = data.pop('product_data', {})
            project_data = {
                'product': {
                    'name': product_data.get('name'),
                    'version': product_data.get('version'),
                    'alias': product_data.get('alias', '')
                },
                'distribution': {
                    'name': '',
                    'version': '',
                    'arch': '',
                    'alias': product_data.get('distribution'),
                },
                'product_distribution': {
                    'name': '',
                    'version': '',
                    'arch': '',
                    'alias': product_data.get('distribution'),
                },
                'commit': None,
                'spec_project': '',
                'source_project': '',
                'branch': None,
                'type': product_data.get('type'),
                'patches': [],
            }
            branches = product_data.get('branches', list())
            if len(branches) == 0:
                branches.append(product_data.get('branch'))
            for branch in branches:
                try:
                    if product_data.get('type') == 'deb':
                        parser = DebProjectParser(project_config)
                    elif product_data.get('type') == 'rpm':
                        parser = RpmProjectParser(project_config)
                    else:
                        parser = None

                    parser.parse(product_data, project_data, branch)

                    self.log.debug('Sending data to result_queue')
                    self.result_queue.put({
                        'data': project_data,
                        'worker': self.name
                    })
                    break
                except NoGitBranchException as e:
                    self.log.warning(e)
                except FileNotFoundException as e:
                    self.log.warning(e)
                except: # noqa
                    self.log.exception("Exception while parsing {} ({})"
                                       .format(project_config, branch))


class GitProjectParser(object):
    def __init__(self, project_config):
        self.project_config = project_config
        self.repo = GitRepo(
            store_prefix=self.project_config['git_store_prefix'],
            git_prefix=self.project_config['git_prefix'],
        )


class DebProjectParser(GitProjectParser):
    def parse(self, product_data, project_data, branch):
        if product_data['type'] != 'deb':
            return

        self.repo.import_project(self.project_config['project'],
                                 branch=branch)
        project_data['commit'] = self.repo._.head.commit.hexsha

        spec_path = product_data['spec-dirs'][0]
        control_file = os.path.join(self.repo._.working_dir,
                                    spec_path, 'control')

        if not os.path.exists(control_file):
            raise FileNotFoundException(
                "Control file '{}' not found".format(control_file))

        changelog_file = os.path.join(self.repo._.working_dir,
                                      spec_path, 'changelog')

        if not os.path.exists(changelog_file):
            raise FileNotFoundException(
                "Changelog file '{}' not found".format(changelog_file))

        series_file = os.path.join(self.repo._.working_dir,
                                   spec_path, 'patches/series')

        source_packages = []
        binary_packages = []

        for para in deb822.Sources.iter_paragraphs(
                open(control_file), use_apt_pkg=False):
            if 'Source' in para:
                source_packages.append(para)

        for para in deb822.Packages.iter_paragraphs(
                open(control_file), use_apt_pkg=False):
            if 'Package' in para:
                binary_packages.append(para)

        changelog = Changelog(open(changelog_file), strict=False)

        project_data['branch'] = branch

        project_data['spec_project'] = self.project_config['project']
        project_data['source_project'] = self.project_config['project']\
            .replace('-build', '')

        project_data['source_package'] = source_packages[0]['Source']
        project_data['section_name'] = source_packages[0]['Section']

        for key in ['Build-Depends', 'Build-Depends-Indep']:
            for dep in map(lambda s: s.strip(),
                           source_packages[0].get(key, '').split(',')):
                dep = '|'.join(
                    map(lambda s: s.split()[0] if s else '', dep.split('|')))
                if dep:
                    project_data.setdefault('build_depends', []).append(dep)

        if os.path.exists(series_file):
            for patch_name in open(series_file):
                patch_name = patch_name.rstrip()
                if re.match(r'^\s*#', patch_name):
                    continue
                project_data['patches'].append(patch_name)

        project_data.setdefault('version', {})
        project_data['version'] = {
            'epoch': changelog.epoch or 0,
            'version': changelog.debian_version,
            'revision': changelog.debian_revision,
            'full_version': changelog.full_version
        }
        project_data['upstream_version'] = changelog.upstream_version

        for block in changelog:
            project_data['distribution_version'] = block.version.full_version
            if re.match(r'.*\@(ubuntu|canonical)\.com.*', block.author):
                project_data['distribution']['alias'] = block.distributions
                if 'cloud' in block.version.full_version:
                    project_data['package_origin'] = 'Ubuntu Cloud Archive'
                else:
                    project_data['package_origin'] = 'Ubuntu'
                break
            if re.match(r'.*\@debian\.org.*', block.author):
                project_data['distribution']['alias'] = block.distributions
                project_data['package_origin'] = 'Debian'
                break
        else:
            project_data['package_origin'] = 'Mirantis'

        for package in binary_packages:
            pkg = {}
            pkg['name'] = package['Package']
            for dep in map(lambda s: s.strip(),
                           package.get('Depends', '').split(',')):
                dep = '|'.join(
                    map(lambda s: s.split()[0] if s else '', dep.split('|')))
                if dep:
                    pkg.setdefault('depends', []).append(dep)
            project_data.setdefault('binary_packages', []).append(pkg)


class RpmProjectParser(GitProjectParser):
    def parse(self, product_data, project_data, branch):
        if product_data['type'] != 'rpm':
            return

        self.repo.import_project(self.project_config['project'], branch=branch)
        project_data['commit'] = self.repo._.head.commit.hexsha

        spec_dirs = product_data.get('spec-dirs', ['.', ])
        spec_dir = os.path.join(self.repo._.working_dir, spec_dirs[0])
        spec_file = None
        for file in os.listdir(spec_dir):
            if file.endswith('.spec'):
                spec_file = os.path.join(spec_dir, file)
                break

        if spec_file is None:
            raise FileNotFoundException("No spec file found in '{}'"
                                        .format(spec_dir))
        temp_file = tempfile.mktemp()
        cmd = 'rpmspec --define "_sourcedir {}" --parse {} > {}'\
            .format(self.repo._.working_dir, spec_file, temp_file)
        exit_code = os.system(cmd)
        if exit_code:
            raise Exception("'{}' failed, exit code '{}'"
                            .format(cmd, exit_code))
        spec = Spec.from_file(temp_file)

        sources = []
        binary_packages = []

        project_data['branch'] = branch
        project_data['spec_project'] = self.project_config['project']
        project_data['source_project'] = self.project_config['project']\
            .replace('-build', '')

        for name in spec.sources:
            sources.append(name)

        for package in spec.packages:
            binary_packages.append(package.name)

        project_data['version'] = {
            'epoch': spec.epoch or 0,
            'version': spec.version,
            'revision': spec.release,
            'full_version': '',
        }
        fmt = '{0[version][epoch]}:{0[version][version]}' \
              '-{0[version][revision]}'
        project_data['version']['full_version'] = fmt.format(project_data)
        project_data['upstream_version'] = project_data['version']['version']

        project_data['package_origin'] = 'Undefined'

        project_data['source_package'] = binary_packages[0]
        project_data['binary_packages'] = []
        for name in binary_packages:
            project_data['binary_packages'].append({'name': name})

        for name in spec.patches:
            project_data['patches'].append(name)

        os.remove(temp_file)
